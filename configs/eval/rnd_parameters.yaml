
rnd_train: 
  batch_size: 256
  n_epochs: 250
  lr: 1e-4
  lr_scheduler: cosine
  lr_min: 1e-6
  optimizer: adamw
  weight_decay: 1e-5
  eps: 1e-8
  num_workers: 8
  save_every_n_epochs: 0 # 0 means never save
  keep_checkpoints: 2 # Only apply if save_every_n_epochs > 0
  patience: 7 # Number of epochs to wait before stopping if no improvement
  stop_when_avg_improvement: 0 # 1e-7 # Stop when the absolute improvement over patience iterations is less than this, 0 means never stop
  stop_when_val_to_train_ratio: 10 # Stop when the validation to training loss ratio is larger than this, 0 means never stop
  early_stopping: True
  use_validation: True
  train_ratio: 0.9 # Ratio of training data to validation data
  overwrite: False # Overwrite all models

model_hyperparameters:
  rnd_loss: "l2" # "mse" or "l2"

action_batch_handling: 
  use_action_batch: False
  action_batch_style: "pca" # "svd" or "var" or "pca"
  pca_components: 5 # Number of PCA modes to keep
  pca_part_trajectory: True # Whether to use the entire trajectory or just start, end, and middle
  svd_components: 5 # Number of SVD modes (right singular vectors) to keep
  svd_project: True # Project the executed action onto the SVD space
  svd_num_sigmas : 10 # Number of singular values to keep
  var_factor: 2 # How to scale the variance of the action batch when including in the loss
  max_var_batches: 32 # Maximum number of action batches to use (due to memory constraints)
  mean_factor: 0.1 # How to scale the mean of the action batch when including in the loss

hparams:
  model:
    seed: ${eval.seed} # Seed for the model, used to identify the model in results (overwritten by pipeline seed)
    action_batch_handling: ${eval.action_batch_handling}
    model_hyperparameters: ${eval.model_hyperparameters}
    rnd_train: ${eval.rnd_train}